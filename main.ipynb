{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edbd1848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports,\n",
    "import time\n",
    "import random\n",
    "import string\n",
    "import datetime\n",
    "\n",
    "# Third-party imports,\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset import MNIST\n",
    "\n",
    "# Torch imports,\n",
    "import torch\n",
    "from torchsummary import summary\n",
    "import torch.nn.functional as Encoder\n",
    "from torchvision import datasets\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90055c1",
   "metadata": {},
   "source": [
    "## LeNet-5 Model & Training Method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a77273d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigDataset(Dataset):\n",
    "    def __init__(self, path):\n",
    "        \"\"\"X is the training input while Y is the target output.\"\"\"\n",
    "\n",
    "        # Loading PyTorch dataset,\n",
    "        dataset = torch.load(path)\n",
    "        self.X = dataset.X\n",
    "        self.Y = dataset.Y\n",
    "        del dataset\n",
    "\n",
    "        # One-hot encoding the target output,\n",
    "        print(\"INFO: One-hot encoding target labels.\")\n",
    "        self.Y = Encoder.one_hot(self.Y, num_classes = 10).to(torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the number of objects in the dataset.\"\"\"\n",
    "        return self.X.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"Returns a tuple of training input and target output.\"\n",
    "        return self.X[index], self.Y[index]\n",
    "\n",
    "class NeuralNetwork(torch.nn.Module):\n",
    "    \"\"\"The neural network architecture.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Creating the layer stucture and activation functions of the neutral network.\"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # Layers,\n",
    "        self.ConvolutionalLayer_INPUT = torch.nn.Conv2d(in_channels = 1, out_channels = 6, kernel_size = (5, 5), stride = (1,1), padding = (2,2))\n",
    "        self.PoolingLayer_HIDDEN_1 = torch.nn.AvgPool2d(kernel_size = (2,2), stride = (2,2))\n",
    "        self.ConvolutionalLayer_HIDDEN_2 = torch.nn.Conv2d(in_channels = 6, out_channels = 16, kernel_size = (5, 5), stride = (1,1))\n",
    "        self.PoolingLayer_HIDDEN_3 = torch.nn.AvgPool2d(kernel_size = (2,2), stride = (2,2))\n",
    "        self.DenseLayer_HIDDEN_4 = torch.nn.Linear(in_features = 16*5*5, out_features = 120)\n",
    "        self.DenseLayer_HIDDEN_5 = torch.nn.Linear(in_features = 120, out_features = 84)\n",
    "        self.DenseLayer_OUTPUT = torch.nn.Linear(in_features = 84, out_features = 10)\n",
    "\n",
    "        # Activation functions,\n",
    "        self.Sigmoid = torch.nn.Sigmoid()\n",
    "        self.SoftMax = torch.nn.Softmax()\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"Defining the forward propagation.\"\"\"\n",
    "\n",
    "        X = self.ConvolutionalLayer_INPUT(X)\n",
    "        X = self.Sigmoid(self.PoolingLayer_HIDDEN_1(X))\n",
    "        X = self.ConvolutionalLayer_HIDDEN_2(X)\n",
    "        X = self.Sigmoid(self.PoolingLayer_HIDDEN_3(X))\n",
    "\n",
    "        X = X.view(-1, 16*5*5)\n",
    "        X = self.DenseLayer_HIDDEN_4(X)\n",
    "        X = self.DenseLayer_HIDDEN_5(X)\n",
    "        X = self.SoftMax(self.DenseLayer_OUTPUT(X))\n",
    "\n",
    "        return X\n",
    "\n",
    "def TrainModel(training_data, neural_network, model_name, n_epochs = 10, learning_rate = 0.01):\n",
    "\n",
    "    print(model_name)\n",
    "    summary(neural_network, (1, 28, 28))\n",
    "    print(\" \")\n",
    "\n",
    "    # Utilisation of CUDA if possible,\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        print(f'CUDA is available. Using GPU: {torch.cuda.get_device_name(0)}')\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print('CUDA is not available. Using CPU.')\n",
    "\n",
    "    neural_network.to(device)\n",
    "\n",
    "    # Stochastic Gradient Descent (SGD) as optimiser,\n",
    "    optimiser = SGD(neural_network.parameters(), lr = learning_rate)\n",
    "\n",
    "    # Cross-Entropy loss function,\n",
    "    loss_function = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    losses = []\n",
    "    epochs = np.arange(start = 1, stop = n_epochs, step = 1)\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        epoch_loss = []\n",
    "        stopwatch_start = time.time()\n",
    "        for i, (X, Y) in enumerate(training_data):\n",
    "\n",
    "            # Move data to selected device,\n",
    "            X, Y = X.to(device), Y.to(device)\n",
    "\n",
    "            # Back propagation,\n",
    "            optimiser.zero_grad() \n",
    "            loss_value = loss_function(neural_network(X), Y) \n",
    "            epoch_loss.append(loss_value.item())\n",
    "            loss_value.backward(loss_value) \n",
    "            optimiser.step()\n",
    "\n",
    "        stopwatch_stop = time.time()\n",
    "        epoch_time = round(stopwatch_stop - stopwatch_start, 2)\n",
    "        epoch_avgloss = np.mean(epoch_loss)\n",
    "        losses.append(epoch_avgloss)\n",
    "        ETA = str(datetime.timedelta(seconds = (n_epochs - epoch)*epoch_time)).split(\".\")[0]\n",
    "        update_string = f'[Completed Epoch: {epoch}/{n_epochs} - Time Taken: {epoch_time} secs - Loss: {epoch_avgloss:.5f} - ETA: {ETA} ]'\n",
    "        print(update_string)\n",
    "\n",
    "    torch.save(neural_network.state_dict(), f'{model_name}.pth')\n",
    "    return np.array(epochs), np.array(losses)\n",
    "\n",
    "def AssessModel(test_data, neural_network):\n",
    "\n",
    "    X_test = test_data[:][0]\n",
    "    Y_test = test_data[:][1]\n",
    "    Yhat_test = neural_network(X_test)\n",
    "\n",
    "    correct_counter = 0\n",
    "    incorrect_counter = 0\n",
    "    for Y, Yhat in zip(Y_test, Yhat_test):\n",
    "        if Yhat.argmax() == Y.argmax():\n",
    "            correct_counter += 1\n",
    "        else:\n",
    "            incorrect_counter += 1\n",
    "\n",
    "    accuracy = correct_counter/(correct_counter + incorrect_counter)\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4dadef",
   "metadata": {},
   "source": [
    "## Training Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ece9a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: One-hot encoding target labels.\n",
      "Input Batch Shape: torch.Size([5, 1, 28, 28])\n",
      "Target Batch Shape: torch.Size([5, 10])\n",
      "Example Label: tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LeNet-JFW4E\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Conv2d: 1-1                            [-1, 6, 28, 28]           156\n",
      "├─AvgPool2d: 1-2                         [-1, 6, 14, 14]           --\n",
      "├─Sigmoid: 1-3                           [-1, 6, 14, 14]           --\n",
      "├─Conv2d: 1-4                            [-1, 16, 10, 10]          2,416\n",
      "├─AvgPool2d: 1-5                         [-1, 16, 5, 5]            --\n",
      "├─Sigmoid: 1-6                           [-1, 16, 5, 5]            --\n",
      "├─Linear: 1-7                            [-1, 120]                 48,120\n",
      "├─Linear: 1-8                            [-1, 84]                  10,164\n",
      "├─Linear: 1-9                            [-1, 10]                  850\n",
      "├─Softmax: 1-10                          [-1, 10]                  --\n",
      "==========================================================================================\n",
      "Total params: 61,706\n",
      "Trainable params: 61,706\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 0.42\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.05\n",
      "Params size (MB): 0.24\n",
      "Estimated Total Size (MB): 0.29\n",
      "==========================================================================================\n",
      " \n",
      "CUDA is not available. Using CPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prithvi\\AppData\\Local\\Temp\\ipykernel_6604\\2309659645.py:54: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  X = self.SoftMax(self.DenseLayer_OUTPUT(X))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Completed Epoch: 1/25 - Time Taken: 24.8 secs - Loss: 2.05257 - ETA: 0:09:55 ]\n",
      "[Completed Epoch: 2/25 - Time Taken: 26.02 secs - Loss: 1.61114 - ETA: 0:09:58 ]\n",
      "[Completed Epoch: 3/25 - Time Taken: 24.5 secs - Loss: 1.56697 - ETA: 0:08:59 ]\n",
      "[Completed Epoch: 4/25 - Time Taken: 25.58 secs - Loss: 1.54645 - ETA: 0:08:57 ]\n",
      "[Completed Epoch: 5/25 - Time Taken: 24.32 secs - Loss: 1.53053 - ETA: 0:08:06 ]\n",
      "[Completed Epoch: 6/25 - Time Taken: 25.87 secs - Loss: 1.52373 - ETA: 0:08:11 ]\n",
      "[Completed Epoch: 7/25 - Time Taken: 26.57 secs - Loss: 1.51946 - ETA: 0:07:58 ]\n",
      "[Completed Epoch: 8/25 - Time Taken: 26.49 secs - Loss: 1.51184 - ETA: 0:07:30 ]\n",
      "[Completed Epoch: 9/25 - Time Taken: 26.62 secs - Loss: 1.50788 - ETA: 0:07:05 ]\n",
      "[Completed Epoch: 10/25 - Time Taken: 26.43 secs - Loss: 1.50459 - ETA: 0:06:36 ]\n",
      "[Completed Epoch: 11/25 - Time Taken: 26.31 secs - Loss: 1.50039 - ETA: 0:06:08 ]\n",
      "[Completed Epoch: 12/25 - Time Taken: 25.71 secs - Loss: 1.50009 - ETA: 0:05:34 ]\n",
      "[Completed Epoch: 13/25 - Time Taken: 25.94 secs - Loss: 1.49874 - ETA: 0:05:11 ]\n",
      "[Completed Epoch: 14/25 - Time Taken: 25.48 secs - Loss: 1.49784 - ETA: 0:04:40 ]\n",
      "[Completed Epoch: 15/25 - Time Taken: 26.29 secs - Loss: 1.49645 - ETA: 0:04:22 ]\n",
      "[Completed Epoch: 16/25 - Time Taken: 25.57 secs - Loss: 1.49553 - ETA: 0:03:50 ]\n",
      "[Completed Epoch: 17/25 - Time Taken: 26.04 secs - Loss: 1.49363 - ETA: 0:03:28 ]\n",
      "[Completed Epoch: 18/25 - Time Taken: 25.4 secs - Loss: 1.49083 - ETA: 0:02:57 ]\n",
      "[Completed Epoch: 19/25 - Time Taken: 25.39 secs - Loss: 1.49672 - ETA: 0:02:32 ]\n",
      "[Completed Epoch: 20/25 - Time Taken: 25.48 secs - Loss: 1.49404 - ETA: 0:02:07 ]\n",
      "[Completed Epoch: 21/25 - Time Taken: 25.64 secs - Loss: 1.49031 - ETA: 0:01:42 ]\n",
      "[Completed Epoch: 22/25 - Time Taken: 25.49 secs - Loss: 1.49042 - ETA: 0:01:16 ]\n",
      "[Completed Epoch: 23/25 - Time Taken: 26.06 secs - Loss: 1.49044 - ETA: 0:00:52 ]\n",
      "[Completed Epoch: 24/25 - Time Taken: 25.98 secs - Loss: 1.49002 - ETA: 0:00:25 ]\n",
      "[Completed Epoch: 25/25 - Time Taken: 25.62 secs - Loss: 1.49232 - ETA: 0:00:00 ]\n",
      "INFO: One-hot encoding target labels.\n",
      "Accuracy: 0.9715\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters,\n",
    "EPOCHS = 25\n",
    "BATCH_SIZE = 5\n",
    "LEARNING_RATE = 0.01\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    ID = ''.join(random.choice(string.ascii_uppercase + string.digits) for _ in range(5))\n",
    "    model_name = \"LeNet-\" + ID\n",
    "\n",
    "    # Creating and training neural network,\n",
    "    training_dataset = ConfigDataset(\"training.pt\")\n",
    "    training_dataset_loaded = DataLoader(training_dataset, BATCH_SIZE)\n",
    "    training_dataset_loaded.__dir__()\n",
    "\n",
    "    # Displaying image,\n",
    "    train_features, train_labels = next(iter(training_dataset_loaded))\n",
    "    print(f\"Input Batch Shape: {train_features.size()}\")\n",
    "    print(f\"Target Batch Shape: {train_labels.size()}\")\n",
    "    \n",
    "    random_index = random.randint(0, BATCH_SIZE - 1)\n",
    "    label = train_labels[random_index]\n",
    "    print(f\"Example Label: {label}\")\n",
    "\n",
    "    img = train_features[random_index].squeeze()\n",
    "    label = train_labels[random_index]\n",
    "    plt.imshow(img, cmap = \"gray\")\n",
    "    plt.show()\n",
    "    print(\"\")\n",
    "\n",
    "    # Creating and training neural network,\n",
    "    neural_network = NeuralNetwork()\n",
    "    epoch_array, loss_array = TrainModel(training_dataset_loaded, neural_network, model_name, EPOCHS, LEARNING_RATE)\n",
    "\n",
    "    # Testing neural network,\n",
    "    test_dataset = ConfigDataset(\"test.pt\")\n",
    "    print(\"Accuracy: \" + str(AssessModel(test_dataset, neural_network)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783fd56b",
   "metadata": {},
   "source": [
    "## Model Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29abe09f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (ConvolutionalLayer_INPUT): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (PoolingLayer_HIDDEN_1): AvgPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0)\n",
       "  (ConvolutionalLayer_HIDDEN_2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (PoolingLayer_HIDDEN_3): AvgPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0)\n",
       "  (DenseLayer_HIDDEN_4): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (DenseLayer_HIDDEN_5): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (DenseLayer_OUTPUT): Linear(in_features=84, out_features=10, bias=True)\n",
       "  (Sigmoid): Sigmoid()\n",
       "  (SoftMax): Softmax(dim=None)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_FILE = \"LeNet-JFW4E.pth\"\n",
    "\n",
    "# Loading model,\n",
    "model = NeuralNetwork()\n",
    "model.load_state_dict(torch.load(MODEL_FILE))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a02666",
   "metadata": {},
   "source": [
    "## Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e394d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: One-hot encoding target labels.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prithvi\\AppData\\Local\\Temp\\ipykernel_6604\\2309659645.py:54: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  X = self.SoftMax(self.DenseLayer_OUTPUT(X))\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhgAAAETCAYAAAB0q39OAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAgSUlEQVR4nO3de5RdZZnn8d9D5UYuJAQwEEgIkSxYKNOgEWySkchFkYuAIAu6gcC0K3QbRnToaRhahoDCuFoRe6a5KxdFEBagwW5EwMZmuA4BAonhIqZDJyE3ArkTc3vmj7Mjh6LqfXbVeeucU3W+n7WyUnV++/LWyT5vntr77OeYuwsAACCnHRo9AAAA0PdQYAAAgOwoMAAAQHYUGAAAIDsKDAAAkB0FBgAAyI4CAwDQbWa2wMyOKr6+xMx+2OgxoTlQYLSQ6okAQN9nZqeb2bNmtt7Mlhdff9XMrCf25+5XuftXat2OmY0zMzezfollZhTLXNDu8QuKx2fUOg7UhgIDAPogM7tQ0j9K+q6k3SWNkvTXkiZJGtDJOm11G2Aer0s6u91jU4vH0WAUGC3IzM4xsyfN7BozW2Vm883ssOLxhcVvOlOrlj/OzF40szVFPqPd9s42szfNbKWZXdrulOkOZnaxmf2hyO8xs5F1/pGBlmJmwyVdIemr7n6vu6/1ihfd/S/d/Y/FcreZ2fVm9qCZrZf02RKv97OqXu9/3y6bYWZ3VH3/aTN7qphnXjKzKVXZb83sW8VctNbMHjazXYv48eLvVWa2zsz+vJMf9TlJg83sY8U2PyZpUPH49v3sbGb/bGYrzOzd4uu92o3jf5nZ/yt+5pnMUXlQYLSuQyW9LGkXSXdK+pmkT0naV9KZkv7JzIYWy65X5beEEZKOk/Q3ZnaSJJnZAZKuk/SXkvaQNFzSnlX7+a+STpJ0uKTRkt6VdG2P/VQAJOnPJQ2UNLPEsn8h6UpJwyQ9ofj1fr2ks1R5Pe8iaa8PbbGy7J6S/kXStyWNlPS3ku4zs93a7ftcSR9R5azK3xaPf6b4e4S7D3X3pxPj/4neP4sxtfi+2g6SbpW0t6Sxkt6T9E/tljlb0n9RZQ7bIul/J/aHkigwWte/u/ut7r5V0t2Sxki6wt3/6O4PS9qkSrEhd/+tu89x923u/rKku1QpGCTpVEm/dPcn3H2TpP8pqfoDbv5a0t+7+6Lit6YZkk5NXVsFULNdJb3t7lu2P1B1JuE9M/tM1bIz3f3J4vW9scTr/Z/d/fHi9XyppG2djOFMSQ+6+4PFth6RNEvSsVXL3Orur7v7e5LukXRQN37WOySdYWb9JZ1efP8n7r7S3e9z9w3uvlaVYurwdtv4ibvPdff1xc90Wi+8XNR0KDBa17Kqr9+TJHdv/9hQSTKzQ83sseIU42pViobtpzJHS1q4fSV33yBpZdV29pb082JiWyXpFUlbVbkeDKBnrJS0a3Uh7+6HufuIIque+xdWr9jF1/t6ffD1Xm1vSV/e/tovXv+TVTlLsN3Sqq83qJhzusLd/0PSG5KukvR7d2//8ww2sxuLyzprVLn8MqJdAVG9zpuS+uv9nxndRIGBMu6U9ICkMe4+XNINkra/C32Jqk6RmtmOqpw23W6hpC+4+4iqP4PcfXGdxg60oqcl/VHSiSWWbf+R2tHrfcz2Bc1ssD74eq+2UJUzA9Wv/SHu/p1ujCnyY0kXFn+3d6Gk/SQd6u476f3LL9V30oyp+nqspM2S3u7iGNAOBQbKGCbpHXffaGaHqHLddLt7JZ1QvEl0gCqXQKpfuDdIutLM9pYkM9vNzMpMegC6yd1XSbpc0nVmdqqZDSvecH2QpCHB6tHr/Xgzm1y83q9Q5/+P3KHK3PB5M2szs0FmNqX6DZYJK1S59DK+xLJS5TLv51S5zNLRz/OeKm8YHSnpsg6WOdPMDigKpisk3VtcPkYNKDBQxlclXWFma1V5j8WfXsTu/jtV3sj5M1V+u1knabkqvz1JldvkHpD0cLH+M6q8wRRAD3L3f5D03yT9nSqXRJdJulHSRZKeSqwavd6nq3KWY4kqb9pe1Mn+F6pyBuUSVQqGhZL+u0r8v1Ncar1S0pPF5ZVPB8u/5+6PFu/laO8HknZU5YzEM5Ie6mCZn0i6TZVLNoMkfS0aI2Lm3tUzUUDnijtPVkma4O7/3uDhAECSmf1W0h3uTgfSzDiDgZqZ2QnFG6mGSPqepDmSFjR2VACARqLAQA4nSnqr+DNB0unOqTEAaGlcIgEAANlxBgMAAGRHgQEAALKrqV2zmR2jym2IbZJ+GDVQMTOuxwBNxN175GO7u6Kr80ibmacmrmhSKzPpddb7eruNQT4oyDcFeTRRRtuXKvdlpkQ/Y9QsY6cgH1DrBqTKJ5Sk9IsWGBPkq4N8c5BL0n+k48XBv+aGdPzHNel8SzrW+iCXKr0FUjq693e7zZK2dDKPdPs9GEWb1dclHa3KfdDPSTrD3ecl1qHAAJpIowuM7swjA818j85CSbslsjK5JK0N8teC/IAgXxjkUQGzX5BL0oFBHv3Hc1iQHxXkYzv7/NOyG5Ck84P8I98IFvh+kP9LkC8NcqnSNiThfwTl5Evp+A+/SufvpONkw5PtngjyVxPZG5Le62QeqeUSySGS3nD3+cWHXP1M5drSAsB2zCNAH1VLgbGnPliIL9IHP6YbACLMI0Af1eMfmW1m0yRN6+n9AOi7qucRPkMb6B1qKTAW64PvoNmreOwD3P0mSTdJvAcDwId0eR4ZyDwC9Aq1XCJ5TtIEM9un+FS901X5UCsAKIt5BOijaurkaWbHqvJJdW2SbnH3K4Pl+c0DaCKNvotE6vo80mbmqds0o7sjR5cYU3SHRfTO/ejmxsFBHt1F8hdBXsbtQT4yyKPnObqTpsylrsODfN8g3z/I/zXIVwS5JP06yKM7jvoHeXQsjQjyMvfBRGNI/VutkLSpk3mkpvdguPuDkh6sZRsAWhvzCNA30ckTAABkR4EBAACyo8AAAADZUWAAAIDsKDAAAEB2FBgAACC7mvpgdHln9MEAmkoz9MHoqh3NPNX/YJdg/TK9DbYGedQHY1iQrwzy6Gco83Ht0Se2/iDIxwf5lKHBAhOCvMxH2kXNMs4O8rFRN4+/C/JxQS5JHwvyP6Tj2Sel80fS8dLgR5idjiXV1svjSUmre+DTVAEAADpEgQEAALKjwAAAANlRYAAAgOwoMAAAQHYUGAAAIDsKDAAAkB0FBgAAyK5fowcAAF1hkvon8qjJ1cAS+9gW5FH/p8VBHjXSihp9RXkZ82vcx+7r0vn+LwUbGBLkkjQqyPcL8q1BS7R97g828KUgl+KOYR9Pxwf9p3S++OVkvPuu6dWHvJ3OJWmnIE+9plKvBc5gAACA7CgwAABAdhQYAAAgOwoMAACQHQUGAADIjgIDAABkR4EBAACyM3ev387M6rezFrbvvvsm8+nTpyfzU089NZnPmTMnHMNpp52WzNetC26iR124uzV6DF21o5mnjvBxwfqjS+xjUJCvDPLNQR712XguyA8McklaH+TPlthGs4taaUS/QY8P8vNKjGHqF4IF0tOttCLI70rHzz+czq8ONi/Fx0LqWFopaXMn8whnMAAAQHYUGAAAIDsKDAAAkB0FBgAAyI4CAwAAZEeBAQAAsqPAAAAA2fVr9ADwYW1tbcn8nHPOSebf/e53k/mIESO6OKIP2nPPPcNlLrroomR+6aWX1jQGtC6XtDGRb82wj+g3r/QrVFod5EuDPGqNEOWStLbEMr1d/yAfFuTLgnx2iTFMfSpY4BNBHh0Mc9Pxa8Hq84Ncip+n3RJZqqNRTQWGmS1Q5TjeKmmLu0+sZXsAWg/zCNA35TiD8Vl3fzvDdgC0LuYRoI/hPRgAACC7WgsMl/SwmT1vZtM6WsDMppnZLDObVeO+APRNXZpHcrzHAkDPq/USyWR3X2xmH5H0iJm96u6PVy/g7jdJukniw84AdKhL88gg5hGgV6jpDIa7Ly7+Xi7p55IOyTEoAK2DeQTom7pdYJjZEDMbtv1rSZ9TeEMNALyPeQTou2q5RDJK0s/NbPt27nT3h7KMqsVddtllyfyb3/xmTdufPz99Z/T48eNr2r4knX322cn8jTfeSOa33357zWNAr9DleWSbpA2JfFWGQQ0J8lQfDinuU/FWF8bSkTk1rt9XrKoxPzDIy1S6/zloenL4lek86mMxPMijY3VVkEtxq45BiSw1k3e7wHD3+ZL+rLvrAwDzCNB3cZsqAADIjgIDAABkR4EBAACyo8AAAADZUWAAAIDsKDAAAEB25l6/rru0CpdOOumkcJn7778/ma9cuTKZH3300cn8wgsvTOZRn4wNG1JdCCrOO++8ZL7DDuna9ogjjkjm0RhRjrtbo8fQVQPNfK9EvnewftQ3QJL6B/naIF8a5AtLjCFlc43ro+L4ID+sxDYeDfLoWNk3yP8tyAcE+aogl6QTgzz1+T/3S1rRyTzCGQwAAJAdBQYAAMiOAgMAAGRHgQEAALKjwAAAANlRYAAAgOwoMAAAQHb0waizZ555Jlxm4sSJyfyUU05J5jNnzuzSmHrClClTkvmvfvWrZP7CCy8k80mTJnV1SOhAb+yDsaOZp3oH7B6sv6rEPqI+E+lONFLUKWZkiTGkvFXj+qj4RJAfWGIbo4L8gCCfEORzgnx1kP86yCXp0CBPHW/3SlpOHwwAAFAvFBgAACA7CgwAAJAdBQYAAMiOAgMAAGRHgQEAALKjwAAAANlRYAAAgOxotFVnmzdHLXykFStWJPPRo0fnGk6P6d+/fzJ/4oknkvngwYOT+YEHlmmBg0hvbLQ1zMw/mcijxkfLSuwjaqQ1P8jHB/mgII8adS0IcpQzLsijf0dJSrdFlD4V5NHxujHIxwX5s0EuSecEeWo2XilpM422AABAvVBgAACA7CgwAABAdhQYAAAgOwoMAACQHQUGAADIjgIDAABkRx+MOivTB6OtrS2ZH3PMMcn84Ycf7tKYekLUx2LevHnJfMyYMcn8W9/6VjKfMWNGMkdFb+yDMdjM90/kuwXrp4+8ivQrUDogyMcF+Zogj/psvBTkqJ+RQT4gyIcH+bFBfnmQR8eaJF0b5Kn/tW6W9FZ3+2CY2S1mttzM5lY9NtLMHjGz3xd/7xxtB0DrYh4BWk+ZSyS3SWr/K/PFkn7j7hMk/ab4HgA6c5uYR4CWEhYY7v64pHfaPXyipNuLr2+XdFLeYQHoS5hHgNbTr5vrjXL3JcXXS5Vop25m0yRN6+Z+APRd3ZpH0p9yA6BZ1HwXiVfeJdrpmzfd/SZ3n+ju0WfCAGhRXZlHuvtbEYD66m6BsczM9pCk4u/l+YYEoEUwjwB9WHcLjAckTS2+nippZp7hAGghzCNAHxaebTSzuyRNkbSrmS2SdJmk70i6x8z+StKbkk7ryUHig3bcccce3f7AgQOT+VFHHRVu4+KL0zcEjB07tktjau/SSy9N5i+++GK4jZkz+f+sXnLOI670ffkbgvXXlthHqs+GFPe52CvIF5UYA3qHnYI86suyMMhHBHnb3ul856hpi6RvPpfO17zdefZAYr2wwHD3MzqJjozWBQCJeQRoRbQKBwAA2VFgAACA7CgwAABAdhQYAAAgOwoMAACQHQUGAADIziodeuu0M7P67axJ3XDDDeEy06alP7pl8eLFyfy6665L5gMGDEjmxx9/fDL/5Cc/mczLWLp0aTL/2te+lsyvuuqqZL52bdztYNKkScl848aN4TZ6O3e3Ro+hq/qZ+fAa1m8rsczHgzzqkxGN77Ua8wVBjt7jU0F+apCfG+RDDi4xiPFB/mzn0cRl0qxNHc8jnMEAAADZUWAAAIDsKDAAAEB2FBgAACA7CgwAAJAdBQYAAMiOAgMAAGQXflw78jr//PPDZdavX5/Mv/KVryTzK6+8sktjam/16tXJ/MYbbwy38eqrrybz+fPnJ/Nf/vKXyXzRokXJ/KmnnkrmkjR9+vRkfvXVV4fbQP0NVPq2/RXB+iNL7KN/kEf7iDqorAryrUGOvmNNkC8I8jlB/umoqYoUHvBb09NtpziDAQAAsqPAAAAA2VFgAACA7CgwAABAdhQYAAAgOwoMAACQHQUGAADIzty9fjszq9/O+rD9998/mc+ePTuZ9++fvun5iiuuSOaXX355Mq+HAQMGJPM5c6K7w6V33303mU+ePDmZb9myJdxHs3N3a/QYumpnM/9sIo//5WO7B3nU52JhjetvC3L6ZLSOYUGe/t9A+lyJfRwW5KmuQtdKWtzJPMIZDAAAkB0FBgAAyI4CAwAAZEeBAQAAsqPAAAAA2VFgAACA7CgwAABAdhQYAAAgu36NHgC67oQTTkjmUROqqBFXMzTSimzatCmZX3PNNeE2rrvuumR+yimnJPO777473Afy6ydpZCJPH/1S+sipGBPkqf1LcXOk14J8bZCj74iauo2ucfvXl1jmR0G+IpGtT2ThGQwzu8XMlpvZ3KrHZpjZYjObXfw5NtoOgNbFPAK0njKXSG6TdEwHj1/j7gcVfx7MOywAfcxtYh4BWkpYYLj745LeqcNYAPRRzCNA66nlTZ7nm9nLxanPnTtbyMymmdksM5tVw74A9E1dnkfeq+foAHRbdwuM6yV9VNJBkpZIurqzBd39Jnef6O4Tu7kvAH1Tt+aRHes0OAC16VaB4e7L3H2ru2+TdLOkQ/IOC0BfxzwC9G3dKjDMbI+qb0+WNLezZQGgI8wjQN8W9sEws7skTZG0q5ktknSZpClmdpAkl7RA0nk9N8TW079//2T+xS9+sabt33fffTWt3xs89NBD4TLr1q1L5kcccUQypw9GeTnnEVO610XqvnxJ+rMS+5gc5OlXaLpvgCS9EOTDgzzHu2W/EeTRc/BAkEf/DjcHuRQ/T0eW2Eazi/6tDwzy3YJ8fIkxRH1XtiayxxJZWGC4+xkdPBz15QCAP2EeAVoPrcIBAEB2FBgAACA7CgwAAJAdBQYAAMiOAgMAAGRHgQEAALILb1NF/U2enL4DfdKkScl8yZIlyfyWW27p8ph6mwULFoTLPP/888m8Xz9eHs3IJA1M5G3B+hszjGFzkK8K8l2CPOqzkaMPxqogvzfIlwX5qCD/dZBL0rgSy/R2qZ4uUvw8HhDkB5cYQ3Q8L0xkzyUyzmAAAIDsKDAAAEB2FBgAACA7CgwAAJAdBQYAAMiOAgMAAGRHgQEAALLjRv8mdNFFF9W0/re//e1kHvXJaBULF6bu7pbGjBlTp5GgK/op3UdifLD+ohL7eCvI19e4j92CfFOQ53BokJ81I1jgb2ocwOnxIuc9VuM+eoEFQf5EkKdnMWlbiTEMD/I3EtnaRMYZDAAAkB0FBgAAyI4CAwAAZEeBAQAAsqPAAAAA2VFgAACA7CgwAABAdvTBaEL77LNPo4fQ6x1yyCHhMieffHIyv/POO3MNBxm1SRqRyEcF6/8+wxg21Lj+4iBvq3H7ZRwRLXBmkH9kcDpfEzxL34gGIE0L+mDcEW+i6W0O8lSfCUlaHeT9S4xhZJAPSmSpsxScwQAAANlRYAAAgOwoMAAAQHYUGAAAIDsKDAAAkB0FBgAAyI4CAwAAZEeBAQAAsgsbbZnZGEk/VqV/jUu6yd3/0cxGSrpb0jhJCySd5u7v9txQ0UrMLJl/+ctfTubXXnttuI958+Yl81tvvTXcBsrJOY8MkLRXIj88GMuiEuN9Lsi3BfnGII8adW0N8hyODPK39k3nnw9+ilOD7Ue5JP1biWX6uqgxXHSsRY3nJGl8kKeadaVm6jJnMLZIutDdD5D0aUnTzewASRdL+o27T5D0m+J7AOgI8wjQYsICw92XuPsLxddrJb0iaU9JJ0q6vVjsdkkn9dAYAfRyzCNA6+nSezDMbJykgyU9K2mUuy8poqUqdyYGQItjHgFaQ+kCw8yGSrpP0tfdfU115u6uynXVjtabZmazzGxWTSMF0OvlmEfWdLQAgKZTqsAws/6qTAo/dff7i4eXmdkeRb6HpOUdrevuN7n7RHefmGPAAHqnXPPITvUZLoAahQWGVd7O/yNJr7j796uiByRNLb6eKmlm/uEB6AuYR4DWE96mKmmSpLMkzTGz2cVjl0j6jqR7zOyvJL0p6bQeGSGAvoB5BGgxYYHh7k+o81tdo1up0Q1vvfVWMp8wYUIy32+//ZL50KFDk/m6deuSeRljx45N5kcemT50vvSlLyXz4447LpnPnTs3mUvS9OnTk/msWbxtKJec88gOkoYk8gHB+ruV2Mcfgjzax6Ag3z3Ilwb55iAv4/ggPzbIox4VFwX5D4NcklaWWKa3i3qeRMdapMwlxZFBnjoeU5dB6OQJAACyo8AAAADZUWAAAIDsKDAAAEB2FBgAACA7CgwAAJAdBQYAAMjOKu3/67Qzs/rtrBc7+uijk/kvfvGLZD548OBkvnRp+i77zZtrv8t+2LBhyXz48OHJ/KWXXkrm5557bjJ//fXXk7kkbdiwIVymr3P3znpTNK2PmvlViTx95FU+YS1yY5BvC/KBQb5LkKc74Ujrgxz1Ex1vqZ4tUtwzZXyNeZnP6Ng/yP81kf0fSYs6mUc4gwEAALKjwAAAANlRYAAAgOwoMAAAQHYUGAAAIDsKDAAAkB0FBgAAyK5foweAD3vkkUeS+aGHHprML7jggmR+/PHHJ/NHH300mZexadOmZH7nnXcm86effjqZ5+jVgd5pq9J9INIdVqR0l5iKMUH+ZpCvDfIBQZ5+9aCZRH0uRgV51EdjdJD3D/JlQS7Fx2uqK9F7iYwzGAAAIDsKDAAAkB0FBgAAyI4CAwAAZEeBAQAAsqPAAAAA2VFgAACA7Mzd67czs/rtDEDI3a3RY+iq3c38zEQe9QWYX2IfLwR51FtgUJBHvQ+ivgSpPiDbRc9DW4159NtptH6ZTjYbg3xrkNf6HETbl2rvgxGNITqWomMlOtbKmJfIVkva0sk8whkMAACQHQUGAADIjgIDAABkR4EBAACyo8AAAADZUWAAAIDsKDAAAEB2/Ro9AADoCle6P0HU+yDqrSDFvQmifdQq2n6Z/ZfpM9GTY4iewzI21bh+1EMiystYFeSLgjzqaTIiyEfXuH1J2hDk4xNZqkdGeAbDzMaY2WNmNs/MfmdmFxSPzzCzxWY2u/hzbLQtAK2JeQRoPWXOYGyRdKG7v2BmwyQ9b2aPFNk17v69nhsegD6CeQRoMWGB4e5LJC0pvl5rZq9I2rOnBwag72AeAVpPl97kaWbjJB0s6dniofPN7GUzu8XMdu5knWlmNsvMZtU2VAB9Qa3zyHv1GiiAmpQuMMxsqKT7JH3d3ddIul7SRyUdpMpvJld3tJ673+TuE919Yu3DBdCb5ZhHdqzXYAHUpFSBYWb9VZkUfuru90uSuy9z963uvk3SzZIO6blhAujtmEeA1lLmLhKT9CNJr7j796se36NqsZMlzc0/PAB9AfMI0HrK3EUySdJZkuaY2ezisUsknWFmB6lyW/oCSef1wPgA9A3MI0CLMXev387M6rczACF3t0aPoat2MfPPJ/KRwfqrSuxjfo151MxrlyCPTi2XaaIVLRM1YIrWr7XZ2IASy0TPY6rhmiQNCfKBQV5mjKuCfLcgj47X3WvMo+dIio+FdxLZk5JWdzKP0CocAABkR4EBAACyo8AAAADZUWAAAIDsKDAAAEB2FBgAACA7CgwAAJBdmUZbANA0NktaUcP6ZX6rivofRD0g1gZ51N8hhzL9D2pRphdHyrYMY4j+HaK81n9nKX4eVtW4j0FBHvWwaAtyKT5WUn0wtiQyzmAAAIDsKDAAAEB2FBgAACA7CgwAAJAdBQYAAMiOAgMAAGRHgQEAALIzd6/fzsxWSHqz6qFdJb1dtwF0D2OsXbOPT2rNMe7t7rtl3F5dMI/0iGYfn8QYc6nbPFLXAuNDOzeb5e4TGzaAEhhj7Zp9fBJj7M16w/PS7GNs9vFJjDGXeo6RSyQAACA7CgwAAJBdowuMmxq8/zIYY+2afXwSY+zNesPz0uxjbPbxSYwxl7qNsaHvwQAAAH1To89gAACAPqhhBYaZHWNmr5nZG2Z2caPG0RkzW2Bmc8xstpnNavR4JMnMbjGz5WY2t+qxkWb2iJn9vvh75yYc4wwzW1w8l7PN7NgGj3GMmT1mZvPM7HdmdkHxeFM8l4nxNdXz2GjNPodIzCOZx9g0x3+zzyHBGOv2PDbkEomZtUl6XdLRkhZJek7SGe4+r+6D6YSZLZA00d2b5p5mM/uMpHWSfuzuHy8e+wdJ77j7d4pJdmd3v6jJxjhD0jp3/16jxlXNzPaQtIe7v2BmwyQ9L+kkSeeoCZ7LxPhOUxM9j43UG+YQiXkk8xhnqEmO/2afQ4Ix1m0eadQZjEMkveHu8919k6SfSTqxQWPpNdz9cUnvtHv4REm3F1/frsoB1DCdjLGpuPsSd3+h+HqtpFck7akmeS4T48P7mEO6iXmkds0+h0jNMY80qsDYU9LCqu8XqfkmUJf0sJk9b2bTGj2YhFHuvqT4eqmkUY0cTML5ZvZyceqzoadfq5nZOEkHS3pWTfhcthuf1KTPYwP0hjlEYh7JremO/2afQ6TGzSO8ybNzk939E5K+IGl6ccquqXnlelcz3hZ0vaSPSjpI0hJJVzd0NAUzGyrpPklfd/c11VkzPJcdjK8pn0ckMY/k03THf7PPIVJj55FGFRiLJY2p+n6v4rGm4e6Li7+XS/q5Kqdkm9Gy4lrb9mtuyxs8ng9x92XuvtXdt0m6WU3wXJpZf1VedD919/uLh5vmuexofM34PDZQ088hEvNITs12/Df7HFKMoaHzSKMKjOckTTCzfcxsgKTTJT3QoLF8iJkNKd4UIzMbIulzkuam12qYByRNLb6eKmlmA8fSoe0vuMLJavBzaWYm6UeSXnH371dFTfFcdja+ZnseG6yp5xCJeSS3Zjr+m30OkZpjHmlYo63i1pgfSGqTdIu7X9mQgXTAzMar8tuGJPWTdGczjM/M7pI0RZVPw1sm6TJJv5B0j6SxqnzC5Gnu3rA3R3UyximqnI5zSQsknVd1nbLuzGyypP8raY6kbcXDl6hyfbLhz2VifGeoiZ7HRmvmOURiHqlFs88jzT6HBGOs2zxCJ08AAJAdb/IEAADZUWAAAIDsKDAAAEB2FBgAACA7CgwAAJAdBQYAAMiOAgMAAGRHgQEAALL7/6c6qelGdLI7AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 648x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Prediction: 8, Actual: 8]\n"
     ]
    }
   ],
   "source": [
    "test_dataset = ConfigDataset(\"test.pt\")\n",
    "idx = 1562\n",
    "\n",
    "# Forward pass,\n",
    "X_sample = test_dataset[:][0][idx]\n",
    "X_sample = X_sample.unsqueeze(0)\n",
    "X_sample.requires_grad = True\n",
    "\n",
    "Y_sample = test_dataset[:][1][idx]\n",
    "Y_pred = model(X_sample)\n",
    "\n",
    "# Computing gradients with respect to the loss function via back propagation,\n",
    "loss = Y_pred.max()\n",
    "loss.backward()\n",
    "\n",
    "# Calculate feature importance as the absolute mean of gradients found,\n",
    "feature_importance = torch.abs(X_sample.grad).numpy().squeeze(0)\n",
    "feature_image = feature_importance.reshape((28, 28, 1))\n",
    "image = X_sample.detach().numpy().reshape((28, 28, 1))\n",
    "\n",
    "# Plotting, \n",
    "figure, axis = plt.subplots(1, 2, figsize = (9, 9))\n",
    "axis[0].imshow(image, cmap = \"gray\")\n",
    "axis[0].set_title(\"Image\")\n",
    "axis[1].imshow(feature_image, cmap = \"hot\")\n",
    "axis[1].set_title(\"Gradient Map\")\n",
    "plt.show()\n",
    "print(f\"[Prediction: {Y_pred.detach().numpy().argmax()}, Actual: {Y_sample.numpy().argmax()}]\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
